{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KQrvcjglL3G"
      },
      "outputs": [],
      "source": [
        "To solve the given questions, we will use the requests library to fetch the HTML content of the YouTube channel page,\n",
        " and BeautifulSoup for parsing the HTML content and extracting the required information. We'll then use the csv module to save the extracted data into a CSV file.\n",
        "\n",
        "Here's the Python code to extract the requested information from the given URL:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "# Function to extract video details\n",
        "def extract_video_details(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    video_list = soup.find_all('a', class_='yt-simple-endpoint style-scope ytd-grid-video-renderer')\n",
        "    video_data = []\n",
        "    for video in video_list[:5]:\n",
        "        video_url = 'https://www.youtube.com' + video['href']\n",
        "        thumbnail_url = video.find('img', class_='style-scope yt-img-shadow')['src']\n",
        "        title = video.find('yt-formatted-string', class_='style-scope ytd-grid-video-renderer').text\n",
        "        views = video.find('span', class_='style-scope ytd-grid-video-renderer').text.split()[0]\n",
        "        post_time = video.find('span', class_='style-scope ytd-grid-video-renderer').text.split()[-2:]\n",
        "        video_data.append([video_url, thumbnail_url, title, views, ' '.join(post_time)])\n",
        "    return video_data\n",
        "\n",
        "# Write data to CSV file\n",
        "def write_to_csv(data):\n",
        "    with open('youtube_videos.csv', 'w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(['Video URL', 'Thumbnail URL', 'Title', 'Views', 'Posting Time'])\n",
        "        writer.writerows(data)\n",
        "\n",
        "# Extract video details from the URL\n",
        "url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
        "video_details = extract_video_details(url)\n",
        "\n",
        "# Write data to CSV file\n",
        "write_to_csv(video_details)\n"
      ],
      "metadata": {
        "id": "4Kfq1z9dl1XW"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}